# -*- coding: utf-8 -*-
"""Proyek Akhir : Membuat Model Sistem Rekomendasi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yw4nVIRCIZYWqE9TP89iIPZpislM_7p8

# Data Understanding
"""

# Download dataset
!kaggle datasets download -d haryodwi/database-film-indonesia

# Melakukan ekstraksi pada file zip
!unzip /content/database-film-indonesia.zip

# Cek dokumentasi dataset
import pandas as pd

movies = pd.read_csv('/content/indonesian_movies.csv')

movies.head()

# Menambahkan kolom user_id
movies['user_id'] = ['U' + str(i).zfill(3) for i in range(1, len(movies) + 1)]
movies

"""Variabel-variabel pada Database Film Indonesia adalah sebagai berikut:
- `movie_id`: ID unik film sesuai dengan yang ada di IMDb.
- `title`: Judul film.
- `year`: Tahun rilis film.
- `description`: Sinopsis singkat mengenai film.
- `genre`: Genre film.
- `rating`: Rating usia film.
- `users_rating`: Rata-rata rating dari pengguna yang memberikan ulasan.
- `votes`: Jumlah pengguna yang memberikan rating terhadap film.
- `languages`: Bahasa yang digunakan dalam film.
- `directors`: Nama sutradara film.
- `actors`: Daftar pemeran utama dalam film.
- `runtime`: Durasi film dalam menit.
- `user_id`: ID unik pengguna.


"""

movies.info()

print('Jumlah data film: ', len(movies.movie_id.unique()))
print('Jumlah genre film: ', len(movies.genre.unique()))
print('Jenis genre film: ', movies.genre.unique())
print('Jumlah data penilaian yang diberikan pengguna: ', len(movies['users_rating'].unique()))

"""Terdapat 1.272 data film yang unik dengan 16 macam genre."""

movies.describe()

"""Dari output di atas, diketahui bahwa skala rating berkisar antara 1,2 hingga 9,4.

# Data Preparation
"""

# Cek missing value dengan fungsi isnull()
movies.isnull().sum()

"""Terdapat banyak missing value pada fitur `description`, `genre`, `rating`, dan `directors`, dan `runtime`. Sebenarnya sayang jika data missing value ini langsung di-drop begitu saja. Namun, kita tidak bisa mengidentifikasi nama data ini termasuk ke dalam kategori mana. Oleh karena itu, untuk saat ini kita akan drop saja missing value ini.

## Mengatasi Missing Value
"""

# Membersihkan missing value dengan fungsi dropna()
movies_clean = movies.dropna()
movies_clean

movies_clean.isnull().sum()

"""Sekarang data sudah bersih.

## Menyamakan Jenis Genre
"""

# Mengurutkan movie berdasarkan movie_id kemudian memasukkannya ke dalam variabel fix_movie
fix_movie = movies_clean.sort_values('movie_id', ascending=True)
fix_movie

# Mengecek berapa jumlah fix_movie
len(fix_movie.movie_id.unique())

# Mengecek genre film yang unik
fix_movie.genre.unique()

# Mengecek genre film Thriller
fix_movie[fix_movie['genre'] == 'Thriller']

"""Sekarang, semua nama film telah memiliki satu kategori genre seperti yang diharapkan."""

# Membuat variabel preparation yang berisi dataframe fix_book kemudian mengurutkan berdasarkan ISBN
preparation = fix_movie
preparation.sort_values('movie_id')

# Membuang data duplikat pada variabel preparation
preparation = preparation.drop_duplicates('movie_id')
preparation

# Mengonversi data series ‘movie_id’ menjadi dalam bentuk list
movie_id = preparation['movie_id'].tolist()

# Mengonversi data series ‘title’ menjadi dalam bentuk list
movie_name = preparation['title'].tolist()

# Mengonversi data series ‘genre’ menjadi dalam bentuk list
movie_genre = preparation['genre'].tolist()

print(len(movie_id))
print(len(movie_name))
print(len(movie_genre))

# Membuat dictionary untuk data `movie_id`, `movie_name`, dan `movie_genre`
movie_new = pd.DataFrame({
    'id': movie_id,
    'movie_name': movie_name,
    'genre': movie_genre
})
movie_new

"""Data kini telah siap untuk dimasukkan ke dalam pemodelan.

# Model Development dengan Content Based Filtering
"""

data = movie_new
data.sample(5)

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data genre
tf.fit(data['genre'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data['genre'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""Nilai yang dimiliki berukuran (286, 11). Nilai 286 merupakan ukuran data dan 11 merupakan matrik kategori genre."""

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan genre
# Baris diisi dengan nama film

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data.movie_name
).sample(10, axis=1).sample(10, axis=0)

"""Output matriks tf-idf di atas menunjukkan nama film 'Hangout' memiliki genre 'comedy'. Hal ini terlihat dari nilai matriks 1.0 pada kategori comedy. Demikian seterusnya.

Sampai di sini, kita telah berhasil mengidentifikasi representasi fitur penting dari setiap kategori masakan dengan fungsi tfidfvectorizer. Kita juga telah menghasilkan matriks yang menunjukkan korelasi antara genre dengan nama film.

## Cosine Similarity
"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama film
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['movie_name'], columns=data['movie_name'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap film
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Dengan cosine similarity, kita berhasil mengidentifikasi kesamaan antara satu film dengan film lainnya. Shape (286, 286) merupakan ukuran matriks similarity dari data yang kita miliki. Berdasarkan data yang ada, matriks di atas sebenarnya berukuran 286 film x 286 film (masing-masing dalam sumbu X dan Y). Artinya, kita mengidentifikasi tingkat kesamaan pada 286 nama film. Tapi tentu kita tidak bisa menampilkan semuanya. Oleh karena itu, kita hanya memilih 10 film pada baris vertikal dan 10 film pada sumbu horizontal seperti pada contoh di atas.

Angka 1.0 yang mengindikasikan bahwa film pada kolom X (horizontal) memiliki kesamaan dengan film pada baris Y (vertikal). Sebagai contoh, film 'Dear Nathan Hello Salma' dan 'Surat Cinta Untuk Starla the Movie' teridentifikasi sama (similar) dengan film 'Dilan 1991'.

Nah, dengan data kesamaan (similarity) restoran yang diperoleh dari kode sebelumnya, kita akan merekomendasikan daftar film yang mirip (similar) dengan film yang sebelumnya pernah ditonton pengguna.

## Mendapatkan Rekomendasi

Di sini, kita membuat fungsi resto_recommendations dengan beberapa parameter sebagai berikut:

- Nama_film : Nama film (index kemiripan dataframe).
- Similarity_data : Dataframe mengenai similarity yang telah kita definisikan sebelumnya.
- Items : Nama dan fitur yang digunakan untuk mendefinisikan kemiripan, dalam hal ini adalah ‘movie_name’ dan ‘genre’.
- k : Banyak rekomendasi yang ingin diberikan.
"""

def movie_recommendations(nama_film, similarity_data=cosine_sim_df, items=data[['movie_name', 'genre']], k=5):
    """
    Rekomendasi Film berdasarkan kemiripan dataframe

    Parameter:
    ---
    nama_film : tipe data string (str)
                Nama Film (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan film sebagai
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---


    Pada index ini, kita mengambil k dengan nilai similarity terbesar
    pada index matrix yang diberikan (i).
    """


    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_film].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop nama_film agar nama film yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_film, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

"""Selanjutnya, mari kita terapkan kode di atas untuk menemukan rekomendasi film yang mirip dengan 'MeloDylan'. Terapkan kode berikut:"""

data[data.movie_name.eq('MeloDylan')]

"""Perhatikanlah, 'MeloDylan' masuk dalam kategori genre 'Drama'. Tentu kita berharap rekomendasi yang diberikan adalah film dengan kategori yang mirip. Nah, sekarang, dapatkan movie recommendation dengan memanggil fungsi yang telah kita definisikan sebelumnya:"""

# Mendapatkan rekomendasi film yang mirip dengan MeloDylan
movie_recommendations('MeloDylan')

"""Yay! Berhasil! Sistem kita memberikan rekomendasi 5 nama film dengan kategori 'genre' **Drama**.

# Model Development dengan Collaborative Filtering

## Data Preparation
"""

# Import library
!pip install tensorflow
import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

# Membaca dataset

df = movies
df

"""Perhatikanlah, data memiliki 1.272 baris dan 12 kolom. Goal proyek kita kali ini adalah menghasilkan rekomendasi sejumlah film yang sesuai dengan preferensi pengguna berdasarkan rating yang telah diberikan sebelumnya.

Dari data rating pengguna, kita akan mengidentifikasi film-film yang mirip dan belum pernah ditonton oleh pengguna untuk direkomendasikan.

## Data Preparation
"""

# Drop kolom yang tidak diperlukan
df = df.drop(['year', 'description', 'genre', 'rating', 'votes', 'languages', 'directors', 'actors', 'runtime'], axis=1)
df

df.isnull().sum()

df = df.drop_duplicates()
df

"""Lakukan persiapan data untuk menyandikan (encode) fitur `user_id` dan `movie_id` ke dalam indeks integer. Terapkan kode berikut."""

# Mengubah user_id menjadi list tanpa nilai yang sama
user_ids = df['user_id'].unique().tolist()
print('list userID: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

# Mengubah movie_id menjadi list tanpa nilai yang sama
movie_ids = df['movie_id'].unique().tolist()

# Melakukan proses encoding placeID
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}

# Melakukan proses encoding angka ke placeID
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}

# Mapping user_id ke dataframe user
df['user'] = df['user_id'].map(user_to_user_encoded)

# Mapping movie_id ke dataframe movie
df['movie'] = df['movie_id'].map(movie_to_movie_encoded)

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah movie
num_movie = len(movie_encoded_to_movie)
print(num_movie)

# Mengubah rating menjadi nilai float
df['users_rating'] = df['users_rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(df['users_rating'])

# Nilai maksimal rating
max_rating = max(df['users_rating'])

print('Number of User: {}, Number of Resto: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

"""## Membagi Data untuk Training dan Validasi"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

"""Selanjutnya, kita bagi data train dan validasi dengan komposisi 80:20. Namun sebelumnya, kita perlu memetakan (mapping) data user dan movie menjadi satu value terlebih dahulu. Lalu, buatlah rating dalam skala 0 sampai 1 agar mudah dalam melakukan proses training."""

# Membuat variabel x untuk mencocokkan data user dan movie menjadi satu value
x = df[['user', 'movie']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df['users_rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""Data telah siap untuk dimasukkan ke dalam model.

## Proses Training

Pada tahap ini, model menghitung skor kecocokan antara pengguna dan film dengan teknik embedding. Pertama, kita melakukan proses embedding terhadap data user dan movie. Selanjutnya, lakukan operasi perkalian dot product antara embedding user dan movie. Selain itu, kita juga dapat menambahkan bias untuk setiap user dan movie. Skor kecocokan ditetapkan dalam skala [0,1] dengan fungsi aktivasi sigmoid.
"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_movie, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movie = num_movie
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.movie_embedding = layers.Embedding( # layer embeddings movie
        num_movie,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movie_bias = layers.Embedding(num_movie, 1) # layer embedding movie bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    movie_vector = self.movie_embedding(inputs[:, 1]) # memanggil layer embedding 3
    movie_bias = self.movie_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)

    x = dot_user_movie + user_bias + movie_bias

    return tf.nn.sigmoid(x) # activation sigmoid

model = RecommenderNet(num_users, num_movie, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Model ini menggunakan BinaryCrossentropy untuk menghitung loss function, Adam (Adaptive Moment Estimation) sebagai optimizer, dan root mean squared error (RMSE) sebagai metrics evaluation."""

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""## Visualisasi Metrik"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""## Mendapatkan Rekomendasi Movie"""

movie_df = movie_new
df = movies

# Mengambil sample user
user_id = df.user_id.sample(1).iloc[0]
movie_watched_by_user = df[df.user_id == user_id]

# Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html
movie_not_watched = movie_df[~movie_df['id'].isin(movie_watched_by_user.movie_id.values)]['id']
movie_not_watched = list(
    set(movie_not_watched)
    .intersection(set(movie_to_movie_encoded.keys()))
)

movie_not_watched = [[movie_to_movie_encoded.get(x)] for x in movie_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_watched), movie_not_watched)
)

for user_id in df['user_id'].unique()[:2]:  # Ambil 2 user pertama
    print(f"\nShowing recommendations for user: {user_id}")
    print('===' * 9)

    movie_watched_by_user = df[df.user_id == user_id]
    movie_not_watched = movie_df[~movie_df['id'].isin(movie_watched_by_user.movie_id.values)]['id']
    movie_not_watched = list(set(movie_not_watched).intersection(set(movie_to_movie_encoded.keys())))

    movie_not_watched = [[movie_to_movie_encoded.get(x)] for x in movie_not_watched]
    user_encoder = user_to_user_encoded.get(user_id)
    user_movie_array = np.hstack(([[user_encoder]] * len(movie_not_watched), movie_not_watched))

    ratings = model.predict(user_movie_array).flatten()
    top_ratings_indices = ratings.argsort()[-10:][::-1]
    recommended_movie_ids = [movie_encoded_to_movie.get(movie_not_watched[x][0]) for x in top_ratings_indices]

    print("Movie with high ratings from user:")
    print('----' * 8)

    top_movie_user = movie_watched_by_user.sort_values(by='users_rating', ascending=False).head(5).movie_id.values
    if len(top_movie_user) == 0:
        print("User belum memberikan rating.")
    else:
        for row in movie_df[movie_df['id'].isin(top_movie_user)].itertuples():
            print(row.movie_name, ":", row.genre)

    print('----' * 8)
    print("Top 10 movie recommendation:")
    print('----' * 8)
    for row in movie_df[movie_df['id'].isin(recommended_movie_ids)].itertuples():
        print(row.movie_name, ":", row.genre)

"""Kita telah berhasil memberikan rekomendasi kepada user. Sebagai contoh, hasil di atas adalah rekomendasi untuk user dengan id U001 dan U002. Dari output tersebut, kita dapat membandingkan antara Movie with high ratings from user dan Top 10 movie recommendation untuk user."""